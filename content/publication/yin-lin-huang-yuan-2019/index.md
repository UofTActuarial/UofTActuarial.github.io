---
# Documentation: https://wowchemy.com/docs/managing-content/

title: On the consistency of penalized MLEs for Erlang mixtures
subtitle: ''
summary: ''
authors:
- Cuihong Yin
- X. Sheldon Lin
- Rongtan Huang
- Haili Yuan
tags:
- Erlang mixture
- Insurance loss modeling
- Penalized maximum likelihood estimates
- Consistency
categories: []
date: '2019-01-01'
lastmod: 2022-05-30T21:02:05-04:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2025-04-02T02:33:43.493174Z'
publication_types:
- '2'
abstract: In Yin and Lin (2016), a new penalty, termed as iSCAD penalty, is proposed
  to obtain the maximum likelihood estimates (MLEs) of the weights and the common
  scale parameter of an Erlang mixture model. In that paper, it is shown through simulation
  studies and a real data application that the penalty provides an efficient way to
  determine the MLEs and the order of the mixture. In this paper, we provide a theoretical
  justification and show that the penalized maximum likelihood estimators of the weights
  and the scale parameter as well as the order of mixture are all consistent.
publication: '*Statistics & Probability Letters*'
doi: https://doi.org/10.1016/j.spl.2018.08.004
---
