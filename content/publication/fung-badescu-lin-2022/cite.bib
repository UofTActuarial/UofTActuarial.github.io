@article{fung_badescu_lin_2022,
 abstract = {The logit-weighted reduced mixture of experts model (LRMoE) is a flexible yet analytically tractable non-linear regression model. Though it has shown usefulness in modeling insurance loss frequencies and severities, model calibration becomes challenging when censored and truncated data are involved, which is common in actuarial practice. In this article, we present an extended expectationâ€“conditional maximization (ECM) algorithm that efficiently fits the LRMoE to random censored and random truncated regression data. The effectiveness of the proposed algorithm is empirically examined through a simulation study. Using real automobile insurance data sets, the usefulness and importance of the proposed algorithm are demonstrated through two actuarial applications: individual claim reserving and deductible ratemaking. },
 author = {Tsz Chai Fung and Andrei L. Badescu and X. Sheldon Lin},
 doi = {10.1080/10920277.2021.2013896},
 eprint = {https://doi.org/10.1080/10920277.2021.2013896},
 journal = {North American Actuarial Journal},
 number = {0},
 pages = {1-25},
 publisher = {Routledge},
 title = {Fitting Censored and Truncated Regression Data Using the Mixture of Experts Models},
 volume = {0},
 year = {2022}
}

